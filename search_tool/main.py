"""
è”ç½‘æœç´¢å·¥å…·ä¸»ç¨‹åº
æä¾›ç»Ÿä¸€çš„ç”¨æˆ·ç•Œé¢å’Œäº¤äº’åŠŸèƒ½
"""

import sys
import os
from typing import Optional, Tuple, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models_registry import get_model_registry, list_models, list_model_info, get_model
from smart_model_selector import (
    get_smart_selector,
    select_model_for_query,
    explain_model_selection,
    select_models_for_query_by_threshold,
)
from parallel_executor import ParallelModelExecutor
from report_aggregator import ReportAggregator


class SearchToolUI:
    """æœç´¢å·¥å…·ç”¨æˆ·ç•Œé¢"""
    
    def __init__(self):
        self.registry = get_model_registry()
        self.model_info = list_model_info()
        self.smart_selector = get_smart_selector()
        self.parallel_executor = ParallelModelExecutor(max_workers=5, timeout=300)
        self.report_aggregator = ReportAggregator()
    
    def show_welcome(self):
        """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ¤– ç»Ÿä¸€è”ç½‘æœç´¢å·¥å…·")
        print("="*80)
        print("æ”¯æŒå¤šç§AIæ¨¡å‹çš„è”ç½‘æœç´¢åŠŸèƒ½")
        print("="*80)
        print("\nğŸ‘‹ ä½ å¥½ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ")
        print("="*80)
    
    def show_model_menu(self):
        """æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©èœå•"""
        print("\n" + "="*80)
        print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨")
        print("="*80)
        
        models = list_models()
        for i, model_key in enumerate(models, 1):
            info = self.model_info.get(model_key, {})
            name = info.get("name", model_key.replace("_", " ").title())
            description = info.get("description", "")
            model_id = info.get("model_id", model_key)
            
            print(f"{i:2d}. {name}")
            print(f"    ğŸ“ {description}")
            print(f"    ğŸ”§ æ¨¡å‹ID: {model_id}")
            print()
        
        print("0. é€€å‡ºç¨‹åº")
        print("ğŸ’¡ ä½ å¯ä»¥é€‰æ‹©æ¨¡å‹(å¯å¤šä¸ª)æé—®ï¼›æˆ–ç›´æ¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹è¿›è¡Œå›ç­”")
        print("-"*80)
        print("ğŸš€ ä½¿ç”¨è¯´æ˜ï¼š")
        print("   â€¢ å•ä¸ªæ¨¡å‹ï¼šç›´æ¥è¾“å…¥æ•°å­— (å¦‚: 1)")
        print("   â€¢ å¤šä¸ªæ¨¡å‹ï¼šè¾“å…¥å¤šä¸ªæ•°å­—ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: 1,3,5)")
        print("   â€¢ æ™ºèƒ½æ¨¡å¼ï¼šç›´æ¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æ¨¡å‹")
        print("-"*80)
    
    def get_user_choice(self) -> Tuple[Optional[int], Optional[str], Optional[str], Optional[list]]:
        """è·å–ç”¨æˆ·é€‰æ‹©æˆ–é—®é¢˜"""
        models = list_models()
        max_choice = len(models)
        
        while True:
            try:
                choice = input(f"è¯·è¾“å…¥é€‰æ‹© (0-{max_choice}) æˆ–ç›´æ¥è¾“å…¥æ‚¨çš„é—®é¢˜: ").strip()
                if not choice:  # å¦‚æœç”¨æˆ·ç›´æ¥æŒ‰å›è½¦ï¼Œæç¤ºä¸€ä¸‹
                    print("ğŸ’¡ ä½ å¯ä»¥é€‰æ‹©æ¨¡å‹(å¯å¤šä¸ª)æé—®ï¼›æˆ–ç›´æ¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„æ¨¡å‹è¿›è¡Œå›ç­”")
                    continue
                
                # å¦‚æœè¾“å…¥æ˜¯0ï¼Œé€€å‡ºç¨‹åº
                if choice == "0":
                    return None, None, None, None
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«é€—å·ï¼ˆå¤šä¸ªæ¨¡å‹é€‰æ‹©ï¼‰
                if "," in choice:
                    try:
                        # è§£æå¤šä¸ªæ•°å­—é€‰æ‹©
                        selected_indices = []
                        for choice_part in choice.split(','):
                            choice_part = choice_part.strip()
                            if choice_part.isdigit():
                                idx = int(choice_part)
                                if 1 <= idx <= max_choice:
                                    selected_indices.append(idx)
                                else:
                                    print(f"âŒ æ— æ•ˆé€‰æ‹© {idx}ï¼Œè¯·è¾“å…¥ 1-{max_choice} ä¹‹é—´çš„æ•°å­—")
                                    break
                            else:
                                print(f"âŒ æ— æ•ˆè¾“å…¥ {choice_part}ï¼Œè¯·è¾“å…¥æ•°å­—")
                                break
                        else:
                            if selected_indices:
                                return "MULTI", None, None, selected_indices
                            else:
                                print("âŒ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹")
                                continue
                    except Exception as e:
                        print(f"âŒ è§£æå¤šä¸ªé€‰æ‹©æ—¶å‡ºé”™: {str(e)}")
                        continue
                
                # å°è¯•è½¬æ¢ä¸ºå•ä¸ªæ•°å­—
                try:
                    choice_num = int(choice)
                    if 1 <= choice_num <= max_choice:
                        return choice_num, None, None, None
                    else:
                        print(f"âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-{max_choice} ä¹‹é—´çš„æ•°å­—")
                except ValueError:
                    # ä¸æ˜¯æ•°å­—ï¼Œå¯èƒ½æ˜¯é—®é¢˜
                    if len(choice) >= 2:  # é—®é¢˜é•¿åº¦è‡³å°‘2ä¸ªå­—ç¬¦
                        return None, choice, None, None
                    else:
                        print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—æˆ–è‡³å°‘2ä¸ªå­—ç¬¦çš„é—®é¢˜")
            except Exception as e:
                print(f"âŒ è¾“å…¥é”™è¯¯: {str(e)}")
    
    def get_query(self) -> str:
        """è·å–ç”¨æˆ·æŸ¥è¯¢"""
        print("\n" + "-"*80)
        print("ğŸ’¬ è¯·è¾“å…¥æ‚¨çš„é—®é¢˜:")
        print("-"*80)
        
        while True:
            query = input("> ").strip()
            if query:
                return query
            else:
                print("âŒ æŸ¥è¯¢å†…å®¹ä¸èƒ½ä¸ºç©ºï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def call_selected_model(self, choice: int, query: str) -> bool:
        """è°ƒç”¨é€‰å®šçš„æ¨¡å‹"""
        models = list_models()
        if choice < 1 or choice > len(models):
            print("âŒ æ— æ•ˆçš„æ¨¡å‹é€‰æ‹©")
            return False
        
        model_key = models[choice - 1]
        info = self.model_info.get(model_key, {})
        model_name = info.get("name", model_key.replace("_", " ").title())
        
        print(f"\nğŸš€ æ­£åœ¨è°ƒç”¨ {model_name} æ¨¡å‹...")
        print("-"*80)
        
        try:
            model = get_model(model_key)
            if model is None:
                print(f"âŒ æ— æ³•è·å– {model_name} æ¨¡å‹å®ä¾‹")
                return False
            
            # è°ƒç”¨æ¨¡å‹å¹¶æ˜¾ç¤ºæµå¼è¾“å‡º
            print(f"ğŸš€ å¼€å§‹è°ƒç”¨ {model_name} æ¨¡å‹...")
            print("-" * 80)
            
            result = model.search(query, streaming=True, suppress_thinking=True)
            
            if result and result[0] is not None:
                print(f"\nâœ… {model_name} å›ç­”å®Œæˆ!")
                return True
            else:
                # é”™è¯¯ä¿¡æ¯å·²ç»åœ¨æ¨¡å‹çš„search_with_retryæ–¹æ³•ä¸­æ˜¾ç¤ºï¼Œè¿™é‡Œä¸éœ€è¦é‡å¤
                return False
                
        except Exception as e:
            print(f"\nâŒ è°ƒç”¨ {model_name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            return False
    
    def handle_smart_query(self, query: str) -> bool:
        """å¤„ç†æ™ºèƒ½æŸ¥è¯¢ï¼šæŒ‰é¡ºåº+åˆé€‚åº¦é€‰æ‹©ï¼Œå¤±è´¥æ—¶æŸ¥å¿«è¡¨æ›¿è¡¥"""
        # å¯¼å…¥å¿«è¡¨æ¨¡å—
        try:
            from prebuilt_fast_table import get_global_prebuilt_fast_table
        except ImportError:
            print("âŒ æ— æ³•å¯¼å…¥å¿«è¡¨æ¨¡å—ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼")
            return self._handle_smart_query_fallback(query)
        
        print("\n" + "="*80)
        print("ğŸš€ æ™ºèƒ½æ¨¡å¼ï¼šæŒ‰é¡ºåº+åˆé€‚åº¦é€‰æ‹©ï¼Œå¤±è´¥æ—¶æŸ¥å¿«è¡¨æ›¿è¡¥")
        print("="*80)
        
        # 1) é¦–æ¬¡é€‰æ‹©ï¼šæŒ‰åŸæ¨¡å‹é¡ºåº+åˆé€‚åº¦é€‰æ‹©ï¼ˆä¸æ£€æµ‹å¯ç”¨æ€§ï¼‰
        print("ğŸ¯ é¦–æ¬¡é€‰æ‹©ï¼šæŒ‰æ¨¡å‹é¡ºåº+åˆé€‚åº¦é€‰æ‹©æ¨¡å‹...")
        
        # è·å–æŒ‰åˆé€‚åº¦æ’åºçš„æ¨¡å‹åˆ—è¡¨
        threshold_models = select_models_for_query_by_threshold(query, threshold_percent=70.0)
        if len(threshold_models) < 3:
            top_models = select_model_for_query(query, top_k=8)  # è·å–æ›´å¤šå€™é€‰
            # åˆå¹¶å¹¶å»é‡
            existing_keys = {mk for mk, _, _ in threshold_models}
            for mk, score, info in top_models:
                if mk not in existing_keys:
                    threshold_models.append((mk, score, info))
                    if len(threshold_models) >= 8:
                        break
        
        if not threshold_models:
            print("âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹")
            return False

        # æ™ºèƒ½é€‰æ‹©æ¨¡å‹æ•°é‡ï¼šä¸å°‘äº3ä¸ªï¼Œæœ€å¤šä¸è¶…è¿‡5ä¸ª
        # 1. å»é‡ï¼šç¡®ä¿æ²¡æœ‰é‡å¤çš„æ¨¡å‹
        unique_models = []
        seen_keys = set()
        for mk, score, info in threshold_models:
            if mk not in seen_keys:
                unique_models.append((mk, score, info))
                seen_keys.add(mk)
        
        # 2. åŠ¨æ€å†³å®šé€‰æ‹©æ•°é‡
        if len(unique_models) <= 3:
            target_count = len(unique_models)  # å¦‚æœåªæœ‰3ä¸ªæˆ–æ›´å°‘ï¼Œå…¨éƒ¨é€‰æ‹©
        elif len(unique_models) <= 5:
            target_count = len(unique_models)  # å¦‚æœ3-5ä¸ªï¼Œå…¨éƒ¨é€‰æ‹©
        else:
            # å¦‚æœè¶…è¿‡5ä¸ªï¼Œé€‰æ‹©å‰5ä¸ªï¼ˆæŒ‰åˆé€‚åº¦æ’åºï¼‰
            target_count = 5
        
        selected_models = unique_models[:target_count]
        
        model_keys = [mk for mk, _, _ in selected_models]
        model_names = [
            self.model_info.get(mk, {}).get("name", mk.replace("_", " ").title())
            for mk in model_keys
        ]

        print(f"âœ… é¦–æ¬¡é€‰æ‹©äº† {len(model_keys)} ä¸ªæ¨¡å‹ï¼ˆæŒ‰åˆé€‚åº¦æ’åºï¼Œå·²å»é‡ï¼‰ï¼š")
        for i, (name, (_, score, _)) in enumerate(zip(model_names, selected_models), 1):
            print(f"   {i}. {name} (åˆé€‚åº¦: {score:.1f}%)")

        # 2) æ‰§è¡Œé€‰æ‹©çš„æ¨¡å‹
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œé¦–æ¬¡é€‰æ‹©çš„æ¨¡å‹...")
        print("="*80)
        
        results = self.parallel_executor.execute_models(
            model_keys=model_keys,
            query=query,
            suppress_thinking=True,
            streaming=True,
        )
        
        # 3) å¤„ç†ç»“æœï¼Œå¦‚æœæœ‰å¤±è´¥çš„æ¨¡å‹ï¼Œä½¿ç”¨å¿«è¡¨æ›¿è¡¥
        if results:
            successful_results = [r for r in results if r.status == "success"]
            failed_results = [r for r in results if r.status != "success"]
            
            print(f"\nğŸ¯ é¦–æ¬¡æ‰§è¡Œå®Œæˆï¼")
            print(f"ğŸ“Š ç»“æœï¼šæˆåŠŸ {len(successful_results)} ä¸ªï¼Œå¤±è´¥ {len(failed_results)} ä¸ª")
            
            # å¦‚æœæœ‰å¤±è´¥çš„æ¨¡å‹ï¼Œä½¿ç”¨å¿«è¡¨æ›¿è¡¥
            if failed_results and len(successful_results) < 3:
                print(f"\nğŸ”„ æ£€æµ‹åˆ°å¤±è´¥æ¨¡å‹ï¼Œä½¿ç”¨å¿«è¡¨æ›¿è¡¥...")
                replacement_success = self._handle_failed_models_with_fast_table(
                    query, failed_results, successful_results, seen_keys
                )
                # æ³¨æ„ï¼š_handle_failed_models_with_fast_table å·²ç»ä¿®æ”¹äº† successful_results å’Œ failed_results
                # ä¸éœ€è¦é‡æ–°è·å–ï¼Œå› ä¸ºæ›¿è¡¥ç»“æœå·²ç»æ·»åŠ åˆ°è¿™ä¸¤ä¸ªåˆ—è¡¨ä¸­äº†
            
            # æœ€ç»ˆç»“æœå¤„ç†
            print(f"\nğŸ¯ æœ€ç»ˆæ‰§è¡Œå®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆç»“æœï¼šæˆåŠŸ {len(successful_results)} ä¸ªï¼Œå¤±è´¥ {len(failed_results)} ä¸ª")
            print("-" * 80)
            
            if successful_results:
                if len(successful_results) >= 2:
                    # å¤šä¸ªæˆåŠŸç»“æœï¼Œç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
                    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
                    # ç¡®ä¿æŠ¥å‘ŠåŒ…å«æ‰€æœ‰æˆåŠŸçš„æ¨¡å‹ï¼ˆåŒ…æ‹¬æ›¿è¡¥çš„ï¼‰
                    report = self.report_aggregator.aggregate_results(query, successful_results)
                    print(f"\nğŸ“‹ æ±‡æ€»æŠ¥å‘Šï¼š")
                    print("="*80)
                    report_text = self.report_aggregator.generate_report(report, "structured")
                    print(report_text)
                    
                    # ä¿®å¤ï¼šæ˜¾ç¤ºæ­£ç¡®çš„æ€»æ¨¡å‹æ•°ï¼ˆåŒ…å«æ›¿è¡¥æˆåŠŸçš„ï¼‰
                    total_successful = len(successful_results)
                    print(f"\nğŸ“Š æŠ¥å‘Šç»Ÿè®¡ï¼š")
                    print(f"   â€¢ æ€»æ¨¡å‹æ•°ï¼š{total_successful}ï¼ˆåŒ…å«æ›¿è¡¥æˆåŠŸï¼‰")
                    print(f"   â€¢ æˆåŠŸæ¨¡å‹ï¼š{total_successful}")
                    print(f"   â€¢ å¤±è´¥æ¨¡å‹ï¼š{len(failed_results)}")
                    print(f"   â€¢ æˆåŠŸç‡ï¼š{(total_successful / (total_successful + len(failed_results)) * 100):.1f}%")

                    # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
                    export_choice = input(f"\nğŸ’¾ æ˜¯å¦å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
                    if export_choice in ['y', 'yes', 'æ˜¯']:
                        filename = self.report_aggregator.export_report(report, "structured")
                        if filename:
                            print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
                        else:
                            print("âŒ å¯¼å‡ºå¤±è´¥")
                else:
                    # åªæœ‰ä¸€ä¸ªæˆåŠŸç»“æœï¼Œæ˜¾ç¤ºå•ä¸ªå›ç­”
                    result = successful_results[0]
                    print(f"\nğŸ“ {result.model_name} çš„å›ç­”ï¼š")
                    print("-" * 80)
                    print(result.response)
                    print("-" * 80)
                
                # æ˜¾ç¤ºå¤±è´¥æ¨¡å‹ä¿¡æ¯
                if failed_results:
                    print(f"\nâš ï¸  å¤±è´¥çš„æ¨¡å‹ï¼š")
                    for result in failed_results:
                        print(f"   â€¢ {result.model_name}: {result.status}")
                
                return True
            else:
                print("âŒ æ²¡æœ‰è·å¾—æœ‰æ•ˆçš„æ¨¡å‹å›ç­”")
                return False
        else:
            print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½è°ƒç”¨å¤±è´¥")
            return False
    
    def _handle_smart_query_fallback(self, query: str) -> bool:
        """æ™ºèƒ½æŸ¥è¯¢çš„å›é€€æ–¹æ³•ï¼ˆä¼ ç»Ÿæ¨¡å¼ï¼‰"""
        print("ğŸ”„ ä½¿ç”¨ä¼ ç»Ÿæ™ºèƒ½æ¨¡å¼ï¼ˆåŸºäºåˆé€‚åº¦é€‰æ‹©ï¼‰...")
        
        # è·å–æŒ‰åˆé€‚åº¦æ’åºçš„æ¨¡å‹åˆ—è¡¨
        threshold_models = select_models_for_query_by_threshold(query, threshold_percent=70.0)
        if len(threshold_models) < 3:
            top_models = select_model_for_query(query, top_k=10)  # è·å–æ›´å¤šå€™é€‰
            # åˆå¹¶å¹¶å»é‡
            existing_keys = {mk for mk, _, _ in threshold_models}
            for mk, score, info in top_models:
                if mk not in existing_keys:
                    threshold_models.append((mk, score, info))
                    if len(threshold_models) >= 10:
                        break
        
        if not threshold_models:
            print("âŒ æ— æ³•æ‰¾åˆ°åˆé€‚çš„æ¨¡å‹")
            return False

        # æ™ºèƒ½é€‰æ‹©æ¨¡å‹æ•°é‡ï¼šä¸å°‘äº3ä¸ªï¼Œæœ€å¤šä¸è¶…è¿‡5ä¸ª
        # 1. å»é‡ï¼šç¡®ä¿æ²¡æœ‰é‡å¤çš„æ¨¡å‹
        unique_models = []
        seen_keys = set()
        for mk, score, info in threshold_models:
            if mk not in seen_keys:
                unique_models.append((mk, score, info))
                seen_keys.add(mk)
        
        # 2. åŠ¨æ€å†³å®šé€‰æ‹©æ•°é‡
        if len(unique_models) <= 3:
            target_count = len(unique_models)  # å¦‚æœåªæœ‰3ä¸ªæˆ–æ›´å°‘ï¼Œå…¨éƒ¨é€‰æ‹©
        elif len(unique_models) <= 5:
            target_count = len(unique_models)  # å¦‚æœ3-5ä¸ªï¼Œå…¨éƒ¨é€‰æ‹©
        else:
            # å¦‚æœè¶…è¿‡5ä¸ªï¼Œé€‰æ‹©å‰5ä¸ªï¼ˆæŒ‰åˆé€‚åº¦æ’åºï¼‰
            target_count = 5
        
        selected_models = unique_models[:target_count]
        
        model_keys = [mk for mk, _, _ in selected_models]
        model_names = [
            self.model_info.get(mk, {}).get("name", mk.replace("_", " ").title())
            for mk in model_keys
        ]

        print(f"âœ… ä¼ ç»Ÿæ¨¡å¼é€‰æ‹©äº† {len(model_keys)} ä¸ªæ¨¡å‹ï¼ˆæŒ‰åˆé€‚åº¦æ’åºï¼Œå·²å»é‡ï¼‰ï¼š")
        for i, (name, (_, score, _)) in enumerate(zip(model_names, selected_models), 1):
            print(f"   {i}. {name} (åˆé€‚åº¦: {score:.1f}%)")

        # æ‰§è¡Œé€‰æ‹©çš„æ¨¡å‹
        print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œä¼ ç»Ÿæ¨¡å¼é€‰æ‹©çš„æ¨¡å‹...")
        print("="*80)
        
        results = self.parallel_executor.execute_models(
            model_keys=model_keys,
            query=query,
            suppress_thinking=True,
            streaming=True,
        )
        
        # å¤„ç†ç»“æœ
        if results:
            successful_results = [r for r in results if r.status == "success"]
            failed_results = [r for r in results if r.status != "success"]
            
            print(f"\nğŸ¯ æ‰§è¡Œå®Œæˆï¼")
            print(f"ğŸ“Š æœ€ç»ˆç»“æœï¼šæˆåŠŸ {len(successful_results)} ä¸ªï¼Œå¤±è´¥ {len(failed_results)} ä¸ª")
            print("-" * 80)
            
            if successful_results:
                if len(successful_results) >= 2:
                    # å¤šä¸ªæˆåŠŸç»“æœï¼Œç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
                    print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
                    report = self.report_aggregator.aggregate_results(query, successful_results)
                    print(f"\nğŸ“‹ æ±‡æ€»æŠ¥å‘Šï¼š")
                    print("="*80)
                    report_text = self.report_aggregator.generate_report(report, "structured")
                    print(report_text)

                    # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
                    export_choice = input(f"\nğŸ’¾ æ˜¯å¦å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
                    if export_choice in ['y', 'yes', 'æ˜¯']:
                        filename = self.report_aggregator.export_report(report, "structured")
                        if filename:
                            print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
                        else:
                            print("âŒ å¯¼å‡ºå¤±è´¥")
                else:
                    # åªæœ‰ä¸€ä¸ªæˆåŠŸç»“æœï¼Œæ˜¾ç¤ºå•ä¸ªå›ç­”
                    result = successful_results[0]
                    print(f"\nğŸ“ {result.model_name} çš„å›ç­”ï¼š")
                    print("-" * 80)
                    print(result.response)
                    print("-" * 80)
                
                # æ˜¾ç¤ºå¤±è´¥æ¨¡å‹ä¿¡æ¯
                if failed_results:
                    print(f"\nâš ï¸  å¤±è´¥çš„æ¨¡å‹ï¼š")
                    for result in failed_results:
                        print(f"   â€¢ {result.model_name}: {result.status}")
                
                return True
            else:
                print("âŒ æ²¡æœ‰è·å¾—æœ‰æ•ˆçš„æ¨¡å‹å›ç­”")
                return False
        else:
            print("âŒ æ‰€æœ‰æ¨¡å‹éƒ½è°ƒç”¨å¤±è´¥")
            return False
    
    def show_model_info(self):
        """æ˜¾ç¤ºæ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        print("\n" + "="*80)
        print("ğŸ“Š æ¨¡å‹è¯¦ç»†ä¿¡æ¯")
        print("="*80)
    
    def handle_multiple_models(self, selected_indices: list) -> bool:
        """å¤„ç†å¤šä¸ªæ¨¡å‹é€‰æ‹©"""
        print("\n" + "="*80)
        print("ğŸš€ å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ¨¡å‹")
        print("="*80)
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        models = list_models()
        
        # è·å–é€‰ä¸­çš„æ¨¡å‹é”®ï¼ˆæ³¨æ„ï¼šselected_indicesæ˜¯ä»1å¼€å§‹çš„ï¼Œéœ€è¦è½¬æ¢ä¸ºä»0å¼€å§‹ï¼‰
        selected_model_keys = [models[i-1] for i in selected_indices]
        selected_model_names = [self.model_info.get(key, {}).get("name", key.replace("_", " ").title()) 
                              for key in selected_model_keys]
        
        print(f"âœ… å·²é€‰æ‹© {len(selected_model_keys)} ä¸ªæ¨¡å‹ï¼š")
        for name in selected_model_names:
            print(f"   â€¢ {name}")
        
        # è·å–æŸ¥è¯¢
        query = self.get_query()
        
        # æ‰§è¡Œå¹¶è¡ŒæŸ¥è¯¢
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(selected_model_keys)} ä¸ªæ¨¡å‹...")
        results = self.parallel_executor.execute_models(
            model_keys=selected_model_keys,
            query=query,
            suppress_thinking=True,
            streaming=True
        )
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        if results:
            print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
            report = self.report_aggregator.aggregate_results(query, results)
            
            # æ˜¾ç¤ºæŠ¥å‘Š
            print(f"\nğŸ“‹ æ±‡æ€»æŠ¥å‘Šï¼š")
            print("="*80)
            report_text = self.report_aggregator.generate_report(report, "structured")
            print(report_text)
            
            # ä¿®å¤ï¼šæ˜¾ç¤ºæ­£ç¡®çš„ç»Ÿè®¡ä¿¡æ¯
            successful_results = [r for r in results if r.status == "success"]
            failed_results = [r for r in results if r.status != "success"]
            total_models = len(results)
            total_successful = len(successful_results)
            total_failed = len(failed_results)
            success_rate = (total_successful / total_models * 100) if total_models > 0 else 0
            
            print(f"\nğŸ“Š æŠ¥å‘Šç»Ÿè®¡ï¼š")
            print(f"   â€¢ æ€»æ¨¡å‹æ•°ï¼š{total_models}")
            print(f"   â€¢ æˆåŠŸæ¨¡å‹ï¼š{total_successful}")
            print(f"   â€¢ å¤±è´¥æ¨¡å‹ï¼š{total_failed}")
            print(f"   â€¢ æˆåŠŸç‡ï¼š{success_rate:.1f}%")
            
            # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
            export_choice = input(f"\nğŸ’¾ æ˜¯å¦å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
            if export_choice in ['y', 'yes', 'æ˜¯']:
                filename = self.report_aggregator.export_report(report, "structured")
                if filename:
                    print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
                else:
                    print("âŒ å¯¼å‡ºå¤±è´¥")
            
            return True
        else:
            print("âŒ å¹¶è¡Œæ‰§è¡Œå¤±è´¥ï¼Œæ²¡æœ‰è·å¾—ç»“æœ")
            return False

    def handle_parallel_execution(self) -> bool:
        """å¤„ç†å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ¨¡å‹ï¼ˆä¿ç•™åŸæœ‰æ–¹æ³•ä»¥å…¼å®¹ï¼‰"""
        print("\n" + "="*80)
        print("ğŸš€ å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ¨¡å‹")
        print("="*80)
        
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
        models = list_models()
        print("ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨ï¼š")
        for i, model_key in enumerate(models, 1):
            info = self.model_info.get(model_key, {})
            name = info.get("name", model_key.replace("_", " ").title())
            print(f"{i:2d}. {name}")
        
        # è·å–ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹
        print(f"\nè¯·é€‰æ‹©è¦å¹¶è¡Œæ‰§è¡Œçš„æ¨¡å‹ï¼ˆè¾“å…¥æ•°å­—ï¼Œç”¨é€—å·åˆ†éš”ï¼Œå¦‚ï¼š1,3,5ï¼‰ï¼š")
        while True:
            try:
                choice_input = input("> ").strip()
                if not choice_input:
                    print("âŒ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹")
                    continue
                
                # è§£æç”¨æˆ·é€‰æ‹©
                selected_indices = []
                for choice in choice_input.split(','):
                    choice = choice.strip()
                    if choice.isdigit():
                        idx = int(choice)
                        if 1 <= idx <= len(models):
                            selected_indices.append(idx)
                        else:
                            print(f"âŒ æ— æ•ˆé€‰æ‹© {idx}ï¼Œè¯·è¾“å…¥ 1-{len(models)} ä¹‹é—´çš„æ•°å­—")
                            break
                    else:
                        print(f"âŒ æ— æ•ˆè¾“å…¥ {choice}ï¼Œè¯·è¾“å…¥æ•°å­—")
                        break
                else:
                    if selected_indices:
                        break
                    else:
                        print("âŒ è¯·é€‰æ‹©è‡³å°‘ä¸€ä¸ªæ¨¡å‹")
                        continue
                        
            except Exception as e:
                print(f"âŒ è¾“å…¥é”™è¯¯: {str(e)}")
        
        # è·å–é€‰ä¸­çš„æ¨¡å‹é”®
        selected_model_keys = [models[i-1] for i in selected_indices]
        selected_model_names = [self.model_info.get(key, {}).get("name", key.replace("_", " ").title()) 
                              for key in selected_model_keys]
        
        print(f"\nâœ… å·²é€‰æ‹© {len(selected_model_keys)} ä¸ªæ¨¡å‹ï¼š")
        for name in selected_model_names:
            print(f"   â€¢ {name}")
        
        # è·å–æŸ¥è¯¢
        query = self.get_query()
        
        # æ‰§è¡Œå¹¶è¡ŒæŸ¥è¯¢
        print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(selected_model_keys)} ä¸ªæ¨¡å‹...")
        results = self.parallel_executor.execute_models(
            model_keys=selected_model_keys,
            query=query,
            suppress_thinking=True,
            streaming=True
        )
        
        # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
        if results:
            print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
            report = self.report_aggregator.aggregate_results(query, results)
            
            # æ˜¾ç¤ºæŠ¥å‘Š
            print(f"\nğŸ“‹ æ±‡æ€»æŠ¥å‘Šï¼š")
            print("="*80)
            report_text = self.report_aggregator.generate_report(report, "structured")
            print(report_text)
            
            # ä¿®å¤ï¼šæ˜¾ç¤ºæ­£ç¡®çš„ç»Ÿè®¡ä¿¡æ¯
            successful_results = [r for r in results if r.status == "success"]
            failed_results = [r for r in results if r.status != "success"]
            total_models = len(results)
            total_successful = len(successful_results)
            total_failed = len(failed_results)
            success_rate = (total_successful / total_models * 100) if total_models > 0 else 0
            
            print(f"\nğŸ“Š æŠ¥å‘Šç»Ÿè®¡ï¼š")
            print(f"   â€¢ æ€»æ¨¡å‹æ•°ï¼š{total_models}")
            print(f"   â€¢ æˆåŠŸæ¨¡å‹ï¼š{total_successful}")
            print(f"   â€¢ å¤±è´¥æ¨¡å‹ï¼š{total_failed}")
            print(f"   â€¢ æˆåŠŸç‡ï¼š{success_rate:.1f}%")
            
            # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
            export_choice = input(f"\nğŸ’¾ æ˜¯å¦å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
            if export_choice in ['y', 'yes', 'æ˜¯']:
                filename = self.report_aggregator.export_report(report, "structured")
                if filename:
                    print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
                else:
                    print("âŒ å¯¼å‡ºå¤±è´¥")
            
            return True
        else:
            print("âŒ å¹¶è¡Œæ‰§è¡Œå¤±è´¥ï¼Œæ²¡æœ‰è·å¾—ç»“æœ")
            return False
    
    # def handle_batch_model_selection(self) -> bool:  # æš‚æ—¶æ³¨é‡Šæ‰
    #     """å¤„ç†æ‰¹é‡æ¨¡å‹é€‰æ‹©"""
    #     print("\n" + "="*80)
    #     print("ğŸ“‹ æ‰¹é‡æ¨¡å‹é€‰æ‹©")
    #     print("="*80)
    #     
    #     # æ˜¾ç¤ºæ¨¡å‹åˆ†ç±»
    #     print("è¯·é€‰æ‹©æ¨¡å‹ç±»åˆ«ï¼š")
    #     print("1. æœç´¢ä¸“ç”¨æ¨¡å‹ï¼ˆGoogle Deep Research, Grokç­‰ï¼‰")
    #     print("2. é€šç”¨AIæ¨¡å‹ï¼ˆGPT, Geminiç­‰ï¼‰")
    #     print("3. ä¸­æ–‡æ¨¡å‹ï¼ˆHunyuan, DeepSeekç­‰ï¼‰")
    #     print("4. è‡ªå®šä¹‰é€‰æ‹©")
    #     
    #     while True:
    #         try:
    #             category_choice = input("è¯·é€‰æ‹©ç±»åˆ« (1-4): ").strip()
    #             if category_choice in ['1', '2', '3', '4']:
    #                 break
    #             else:
    #             print("âŒ è¯·è¾“å…¥ 1-4 ä¹‹é—´çš„æ•°å­—")
    #         except Exception as e:
    #             print(f"âŒ è¾“å…¥é”™è¯¯: {str(e)}")
    #     
    #     # æ ¹æ®ç±»åˆ«é€‰æ‹©æ¨¡å‹
    #     models = list_models()
    #     if category_choice == '1':
    #         # æœç´¢ä¸“ç”¨æ¨¡å‹
    #         search_models = ['google_deep_research', 'google_deep_research_pro', 'grok_deep_search', 'deepseek_search', 'kimi_search']
    #         selected_model_keys = [key for key in search_models if key in models]
    #     elif category_choice == '2':
    #         # é€šç”¨AIæ¨¡å‹
    #         general_models = ['gpt_search', 'gemini_25_flash_all', 'gemini_25_pro_all', 'gpt4_gizmo', 'gpt4_all', 'gpt4o_all']
    #         selected_choice == '3':
    #         # ä¸­æ–‡æ¨¡å‹
    #         chinese_models = ['hunyuan_t1', 'hunyuan_t1_latest', 'deepseek_v3']
    #         selected_model_keys = [key for key in chinese_models if key in models]
    #     else:
    #         # è‡ªå®šä¹‰é€‰æ‹©
    #         return self.handle_parallel_execution()
    #     
    #     if not selected_model_keys:
    #         print("âŒ è¯¥ç±»åˆ«ä¸‹æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")
    #         return False
    #     
    #     print(f"\nâœ… å·²é€‰æ‹© {len(selected_model_keys)} ä¸ªæ¨¡å‹ï¼š")
    #     for key in selected_model_keys:
    #         name = self.model_info.get(key, {}).get("name", key.replace("_", " ").title())
    #         print(f"   â€¢ {name}")
    #     
    #     # è·å–æŸ¥è¯¢
    #     query = self.get_query()
    #     
    #     # æ‰§è¡Œå¹¶è¡ŒæŸ¥è¯¢
    #     print(f"\nğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(selected_model_keys)} ä¸ªæ¨¡å‹...")
    #     results = self.parallel_executor.execute_models(
    #         model_keys=selected_model_keys,
    #         query=query,
    #         suppress_thinking=True,
    #         streaming=False
    #     )
    #     
    #     # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    #     if results:
    #         print(f"\nğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š...")
    #         report = self.report_aggregator.aggregate_results(query, results)
    #             
    #         # æ˜¾ç¤ºæŠ¥å‘Š
    #         print(f"\nğŸ“‹ æ±‡æ€»æŠ¥å‘Šï¼š")
    #         print("="*80)
    #         report_text = self.report_aggregator.generate_report(report, "structured")
    #         print(report_text)
    #             
    #         # è¯¢é—®æ˜¯å¦å¯¼å‡ºæŠ¥å‘Š
    #         export_choice = input(f"\nğŸ’¾ æ˜¯å¦å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶ï¼Ÿ(y/n): ").strip().lower()
    #         if export_choice in ['y', 'yes', 'æ˜¯']:
    #             filename = self.report_aggregator.export_report(report, "structured")
    #             if filename:
    #                 print(f"âœ… æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {filename}")
    #             else:
    #                 print("   ğŸ“ˆ æ€»è®¡: {len(models)} ä¸ªæ¨¡å‹")
    #         print("-"*80)
    
    def show_api_config(self):
        """æ˜¾ç¤ºAPIé…ç½®ä¿¡æ¯"""
        configs = self.registry.get_api_configs()
        print("\n" + "="*80)
        print("âš™ï¸  APIé…ç½®ä¿¡æ¯")
        print("="*80)
        print(f"ä¸»API Base: {configs.get('primary_base', 'N/A')}")
        print(f"ä¸»API Key: {configs.get('primary_key', 'N/A')[:20]}...")
        print(f"å¤‡ç”¨API Base: {configs.get('backup_base', 'N/A')}")
        print(f"å¤‡ç”¨API Key: {configs.get('backup_key', 'N/A')[:20]}...")
        print("-"*80)
    
    def show_help(self):
        """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
        print("\n" + "="*80)
        print("â“ å¸®åŠ©ä¿¡æ¯")
        print("="*80)
        print("ğŸ¯ æ™ºèƒ½æ¨¡å¼:")
        print("   - ç›´æ¥è¾“å…¥é—®é¢˜ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨é€‰æ‹©è‡³å°‘3ä¸ªåˆé€‚çš„æ¨¡å‹")
        print("   - ç³»ç»Ÿä¼šåˆ†æé—®é¢˜ç±»å‹ã€è¯­è¨€ã€å¤æ‚åº¦ç­‰å› ç´ ")
        print("   - è‡ªåŠ¨é€‰æ‹©æœ€åˆé€‚çš„æ¨¡å‹ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨æ›¿æ¢")
        print("   - æ”¯æŒå¤šæ¨¡å‹æ±‡æ€»æŠ¥å‘Šç”Ÿæˆ")
        print("\nğŸ”§ æ‰‹åŠ¨æ¨¡å¼:")
        print("   - è¾“å…¥å¯¹åº”çš„æ•°å­—é€‰æ‹©è¦ä½¿ç”¨çš„æ¨¡å‹")
        print("   - ç„¶åè¾“å…¥æ‚¨æƒ³è¦æœç´¢çš„é—®é¢˜")
        print("   - ç³»ç»Ÿä¼šè°ƒç”¨é€‰å®šçš„æ¨¡å‹è¿›è¡Œè”ç½‘æœç´¢")
        print("\nğŸš€ å¹¶è¡Œæ‰§è¡Œæ¨¡å¼:")
        print("   - ç›´æ¥è¾“å…¥å¤šä¸ªæ•°å­—ï¼Œç”¨é€—å·åˆ†éš” (å¦‚: 1,3,5)")
        print("   - æ”¯æŒåŒæ—¶è°ƒç”¨å¤šä¸ªæ¨¡å‹ï¼Œæé«˜æ•ˆç‡")
        print("   - è‡ªåŠ¨ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šï¼Œå¯¹æ¯”ä¸åŒæ¨¡å‹çš„å›ç­”")
        print("   - å¯é€‰æ‹©å¯¼å‡ºæŠ¥å‘Šåˆ°æ–‡ä»¶")
        print("\nğŸ’¡ æç¤º:")
        print("   - æ‰€æœ‰æ¨¡å‹éƒ½æ”¯æŒè”ç½‘æœç´¢åŠŸèƒ½")
        print("   - ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†APIè´Ÿè½½å’Œé‡è¯•")
        print("   - æ”¯æŒæµå¼è¾“å‡ºï¼Œå®æ—¶æ˜¾ç¤ºå›ç­”å†…å®¹")
        print("   - å¦‚æœä¸»APIä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨API")
        print("   - æ™ºèƒ½æ¨¡å¼æ¨èå‡†ç¡®ç‡åŸºäºé—®é¢˜ç‰¹å¾åˆ†æ")
        print("   - å¹¶è¡Œæ‰§è¡Œæ—¶thinkingè¿‡ç¨‹ä¼šè¢«æŠ‘åˆ¶ï¼Œåªæ˜¾ç¤ºæœ€ç»ˆç»“æœ")
        print("-"*80)
    
    def show_advanced_menu(self):
        """æ˜¾ç¤ºé«˜çº§èœå•"""
        print("\n" + "="*80)
        print("ğŸ”§ é«˜çº§åŠŸèƒ½")
        print("="*80)
        print("1. æŸ¥çœ‹æ¨¡å‹è¯¦ç»†ä¿¡æ¯")
        print("2. æŸ¥çœ‹APIé…ç½®")
        print("3. æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯")
        print("4. è¿”å›ä¸»èœå•")
        print("0. é€€å‡ºç¨‹åº")
        print("-"*80)
    
    def handle_advanced_menu(self):
        """å¤„ç†é«˜çº§èœå•"""
        while True:
            self.show_advanced_menu()
            choice = input("è¯·é€‰æ‹©åŠŸèƒ½ (0-4): ").strip()
            
            if choice == "0":
                return False
            elif choice == "1":
                self.show_model_info()
            elif choice == "2":
                self.show_api_config()
            elif choice == "3":
                self.show_help()
            elif choice == "4":
                return True
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 0-4 ä¹‹é—´çš„æ•°å­—")
    
    def run(self):
        """è¿è¡Œä¸»ç¨‹åº"""
        self.show_welcome()
        
        while True:
            self.show_model_menu()
            choice, smart_query, _, multi_choices = self.get_user_choice()
            
            if choice is None and smart_query is None:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ç»Ÿä¸€è”ç½‘æœç´¢å·¥å…·ï¼Œå†è§ï¼")
                break
            
            # å¤„ç†å¤šä¸ªæ¨¡å‹é€‰æ‹©
            if choice == "MULTI" and multi_choices:
                success = self.handle_multiple_models(multi_choices)
            elif smart_query:
                # å¤„ç†æ™ºèƒ½æŸ¥è¯¢
                success = self.handle_smart_query(smart_query)
            else:
                # æ‰‹åŠ¨é€‰æ‹©å•ä¸ªæ¨¡å‹
                query = self.get_query()
                success = self.call_selected_model(choice, query)
            
            # è¯¢é—®æ˜¯å¦ç»§ç»­
            print("\n" + "-"*80)
            continue_choice = input("æ˜¯å¦ç»§ç»­ä½¿ç”¨å…¶ä»–æ¨¡å‹ï¼Ÿ(y/n/h=å¸®åŠ©): ").strip().lower()
            
            if continue_choice in ['h', 'help', 'å¸®åŠ©']:
                self.show_help()
            elif continue_choice not in ['y', 'yes', 'æ˜¯']:
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ç»Ÿä¸€è”ç½‘æœç´¢å·¥å…·ï¼Œå†è§ï¼")
                break

    def _handle_failed_models_with_fast_table(self, query: str, failed_results: list, successful_results: list, seen_keys: set) -> bool:
        """ä½¿ç”¨é¢„æ„å»ºå¿«è¡¨æ›¿è¡¥å¤±è´¥çš„æ¨¡å‹ï¼ˆæ— éœ€ç­‰å¾…æ£€æµ‹ï¼‰"""
        print("ğŸ”„ ä½¿ç”¨é¢„æ„å»ºå¿«è¡¨æ›¿è¡¥å¤±è´¥çš„æ¨¡å‹...")
        
        try:
            # ä½¿ç”¨é¢„æ„å»ºå¿«è¡¨ç³»ç»Ÿï¼ˆæ— éœ€ç­‰å¾…æ£€æµ‹ï¼‰
            from prebuilt_fast_table import get_global_prebuilt_fast_table
            
            prebuilt_table = get_global_prebuilt_fast_table()
            
            # è·å–å¯ç”¨çš„æ›¿è¡¥æ¨¡å‹ï¼ˆç›´æ¥ä»ç¼“å­˜è¿”å›ï¼Œæ— éœ€æ£€æµ‹ï¼‰
            need_count = max(3 - len(successful_results), 1)  # è‡³å°‘éœ€è¦1ä¸ªæ›¿è¡¥
            available_models = prebuilt_table.get_available_models(
                exclude_keys=seen_keys, 
                min_count=need_count
            )
            
            if not available_models:
                print("âš ï¸  é¢„æ„å»ºå¿«è¡¨ä¸­æ²¡æœ‰å¯ç”¨çš„æ›¿è¡¥æ¨¡å‹")
                return False
            
            # é€‰æ‹©æ›¿è¡¥æ¨¡å‹
            max_replacement = min(len(available_models), 5 - len(successful_results))
            replacement_models = available_models[:max_replacement]
            replacement_keys = [mk for mk, _ in replacement_models]
            
            # è·å–æ¨¡å‹åç§°
            replacement_names = []
            for mk, stability_score in replacement_models:
                model_info = self.model_info.get(mk, {})
                model_name = model_info.get("name", mk.replace("_", " ").title())
                replacement_names.append((mk, model_name, stability_score))
            
            print(f"âœ… é¢„æ„å»ºå¿«è¡¨é€‰æ‹©äº† {len(replacement_models)} ä¸ªæ›¿è¡¥æ¨¡å‹ï¼š")
            for i, (mk, name, stability_score) in enumerate(replacement_names, 1):
                print(f"   {i}. {name} (ç¨³å®šæ€§è¯„åˆ†: {stability_score:.2f})")
            
            # æ‰§è¡Œæ›¿è¡¥æ¨¡å‹
            print(f"\nğŸš€ å¼€å§‹æ‰§è¡Œæ›¿è¡¥æ¨¡å‹...")
            print("="*80)
            
            replacement_results = self.parallel_executor.execute_models(
                model_keys=replacement_keys,
                query=query,
                suppress_thinking=True,
                streaming=True,
            )
            
            if replacement_results:
                # å°†æ›¿è¡¥ç»“æœæ·»åŠ åˆ°æ€»ç»“æœä¸­
                successful_results.extend([r for r in replacement_results if r.status == "success"])
                failed_results.extend([r for r in replacement_results if r.status != "success"])
                
                print(f"âœ… æ›¿è¡¥æ¨¡å‹æ‰§è¡Œå®Œæˆï¼")
                print(f"ğŸ“Š æ›¿è¡¥ç»“æœï¼šæˆåŠŸ {len([r for r in replacement_results if r.status == 'success'])} ä¸ª")
                return True
            else:
                print("âŒ æ›¿è¡¥æ¨¡å‹æ‰§è¡Œå¤±è´¥")
                return False
                
        except Exception as e:
            print(f"âŒ é¢„æ„å»ºå¿«è¡¨æ›¿è¡¥è¿‡ç¨‹å¼‚å¸¸: {str(e)}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    try:
        ui = SearchToolUI()
        ui.run()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­ï¼Œå†è§ï¼")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {str(e)}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIé…ç½®")


if __name__ == "__main__":
    main()
