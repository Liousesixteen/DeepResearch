"""
å¹¶è¡Œæ‰§è¡Œç®¡ç†å™¨æ¨¡å—
æ”¯æŒå¤šæ¨¡åž‹å¹¶è¡Œè°ƒç”¨ï¼Œæé«˜æ‰§è¡Œæ•ˆçŽ‡
"""

import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass
from models_registry import get_model_registry


@dataclass
class ModelResult:
    """æ¨¡åž‹æ‰§è¡Œç»“æžœ"""
    model_key: str
    model_name: str
    response: str
    execution_time: float
    status: str  # "success", "error", "timeout"
    error_message: Optional[str] = None
    raw_completion: Any = None


class ParallelModelExecutor:
    """å¹¶è¡Œæ¨¡åž‹æ‰§è¡Œå™¨"""
    
    def __init__(self, max_workers: int = 5, timeout: int = 300):
        self.max_workers = max_workers
        self.timeout = timeout
        self.registry = get_model_registry()
        self.results: List[ModelResult] = []
        self.lock = threading.Lock()
        # æ·»åŠ è¾“å‡ºé”ï¼Œç”¨äºŽåŒæ­¥æµå¼è¾“å‡º
        self.output_lock = threading.Lock()
        # æ·»åŠ æ¨¡åž‹è¾“å‡ºçŠ¶æ€è·Ÿè¸ª
        self.model_output_status = {}
    
    def execute_models(self, model_keys: List[str], query: str, 
                      suppress_thinking: bool = True, streaming: bool = True) -> List[ModelResult]:
        """
        å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæ¨¡åž‹
        
        Args:
            model_keys: è¦æ‰§è¡Œçš„æ¨¡åž‹é”®åˆ—è¡¨
            query: æŸ¥è¯¢é—®é¢˜
            suppress_thinking: æ˜¯å¦æŠ‘åˆ¶thinkingè¿‡ç¨‹
            streaming: æ˜¯å¦ä½¿ç”¨æµå¼å“åº”
            
        Returns:
            æ‰§è¡Œç»“æžœåˆ—è¡¨
        """
        self.results = []
        print(f"\nðŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(model_keys)} ä¸ªæ¨¡åž‹...")
        print(f"â±ï¸  è¶…æ—¶è®¾ç½®: {self.timeout}ç§’")
        print(f"ðŸ”‡ ThinkingæŠ‘åˆ¶: {'å¼€å¯' if suppress_thinking else 'å…³é—­'}")
        print(f"ðŸ“¡ æµå¼å“åº”: {'å¼€å¯' if streaming else 'å…³é—­'}")
        print("-" * 80)
        
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_model = {
                executor.submit(self._execute_single_model, model_key, query, suppress_thinking, streaming): model_key
                for model_key in model_keys
            }
            
            # æ”¶é›†ç»“æžœ
            completed_count = 0
            for future in as_completed(future_to_model, timeout=self.timeout):
                model_key = future_to_model[future]
                try:
                    result = future.result()
                    if result:
                        with self.lock:
                            self.results.append(result)
                        completed_count += 1
                        print(f"âœ… {result.model_name} æ‰§è¡Œå®Œæˆ ({result.execution_time:.2f}s)")
                except TimeoutError:
                    print(f"â° {model_key} æ‰§è¡Œè¶…æ—¶")
                    with self.lock:
                        self.results.append(ModelResult(
                            model_key=model_key,
                            model_name=model_key.replace("_", " ").title(),
                            response="",
                            execution_time=self.timeout,
                            status="timeout",
                            error_message="æ‰§è¡Œè¶…æ—¶"
                        ))
                except Exception as e:
                    print(f"âŒ {model_key} æ‰§è¡Œå¤±è´¥: {str(e)}")
                    with self.lock:
                        self.results.append(ModelResult(
                            model_key=model_key,
                            model_name=model_key.replace("_", " ").title(),
                            response="",
                            execution_time=0,
                            status="error",
                            error_message=str(e)
                        ))
        
        total_time = time.time() - start_time
        print(f"\nðŸŽ¯ å¹¶è¡Œæ‰§è¡Œå®Œæˆï¼")
        print(f"ðŸ“Š æ€»è®¡: {len(model_keys)} ä¸ªæ¨¡åž‹")
        print(f"âœ… æˆåŠŸ: {len([r for r in self.results if r.status == 'success'])} ä¸ª")
        print(f"âŒ å¤±è´¥: {len([r for r in self.results if r.status != 'success'])} ä¸ª")
        print(f"â±ï¸  æ€»è€—æ—¶: {total_time:.2f}ç§’")
        print("-" * 80)
        
        return self.results
    
    def _execute_single_model(self, model_key: str, query: str, 
                            suppress_thinking: bool, streaming: bool) -> Optional[ModelResult]:
        """æ‰§è¡Œå•ä¸ªæ¨¡åž‹"""
        start_time = time.time()
        
        try:
            # èŽ·å–æ¨¡åž‹å®žä¾‹
            model_class = self.registry.get_model_class(model_key)
            if not model_class:
                raise ValueError(f"æ¨¡åž‹ {model_key} ä¸å­˜åœ¨")
            
            # èŽ·å–æ¨¡åž‹ä¿¡æ¯
            model_info = self.registry.get_model_info(model_key)
            model_name = model_info.get("name", model_key.replace("_", " ").title())
            
            # åˆ›å»ºæ¨¡åž‹å®žä¾‹
            model = model_class(self.registry._api_configs)
            
            # è®¾ç½®æ¨¡åž‹æ ‡è¯†ï¼Œç”¨äºŽæµå¼è¾“å‡ºåŒæ­¥
            if hasattr(model, 'set_output_context'):
                model.set_output_context(self.output_lock, model_name)
            
            # æ‰§è¡ŒæŸ¥è¯¢
            with self.output_lock:
                print(f"ðŸ”„ æ­£åœ¨æ‰§è¡Œ {model_name}...")
            
            response, completion = model.search_with_retry(
                query=query,
                streaming=streaming,
                suppress_thinking=suppress_thinking
            )
            
            if response:
                execution_time = time.time() - start_time
                return ModelResult(
                    model_key=model_key,
                    model_name=model_name,
                    response=response,
                    execution_time=execution_time,
                    status="success",
                    raw_completion=completion
                )
            else:
                raise ValueError("æ¨¡åž‹è¿”å›žç©ºå“åº”")
                
        except Exception as e:
            execution_time = time.time() - start_time
            return ModelResult(
                model_key=model_key,
                model_name=model_key.replace("_", " ").title(),
                response="",
                execution_time=execution_time,
                status="error",
                error_message=str(e)
            )
    
    def get_successful_results(self) -> List[ModelResult]:
        """èŽ·å–æˆåŠŸçš„æ‰§è¡Œç»“æžœ"""
        return [r for r in self.results if r.status == "success"]
    
    def get_failed_results(self) -> List[ModelResult]:
        """èŽ·å–å¤±è´¥çš„æ‰§è¡Œç»“æžœ"""
        return [r for r in self.results if r.status != "success"]
    
    def get_execution_summary(self) -> Dict[str, Any]:
        """èŽ·å–æ‰§è¡Œæ‘˜è¦"""
        total = len(self.results)
        successful = len(self.get_successful_results())
        failed = len(self.get_failed_results())
        
        if successful > 0:
            avg_time = sum(r.execution_time for r in self.get_successful_results()) / successful
            min_time = min(r.execution_time for r in self.get_successful_results())
            max_time = max(r.execution_time for r in self.get_successful_results())
        else:
            avg_time = min_time = max_time = 0
        
        return {
            "total_models": total,
            "successful": successful,
            "failed": failed,
            "success_rate": successful / total if total > 0 else 0,
            "average_time": avg_time,
            "min_time": min_time,
            "max_time": max_time
        }
